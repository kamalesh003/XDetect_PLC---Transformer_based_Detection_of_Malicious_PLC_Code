{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u6hnuguL_r0J",
    "outputId": "9ffdeaa6-f412-40de-f677-040ea4e8a594"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/UniboSecurityResearch/PLC-LD-dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vJNz5aKxrh4u",
    "outputId": "f6c33a0c-4d78-4ef7-98f3-399f553ae0eb"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets accelerate torch xmltodict evaluate peft optuna wandb scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "id": "DNJ5pjIJrmZT",
    "outputId": "44872f1b-1e56-4814-a0ee-c2f6b895b599"
   },
   "outputs": [],
   "source": [
    "# 2. Imports & Config\n",
    "import os\n",
    "import xmltodict\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    "    set_seed\n",
    ")\n",
    "import wandb\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    legit_dir: str = \"/content/PLC-LD-dataset/legitimate\"\n",
    "    mal_dir: str   = \"/content/PLC-LD-dataset/malicious\"\n",
    "    model_name: str = \"microsoft/codebert-base\"\n",
    "    output_dir: str = \"/content/model_output\"\n",
    "    max_length: int = 512\n",
    "    train_batch_size: int = 16\n",
    "    eval_batch_size: int  = 32\n",
    "    epochs: int     = 100\n",
    "    lr: float       = 2e-5\n",
    "    weight_decay: float = 0.01\n",
    "    seed: int       = 42\n",
    "    eval_split: float = 0.2\n",
    "    accum_steps: int = 2\n",
    "    fp16: bool      = True\n",
    "    logging_steps: int = 100\n",
    "    save_steps: int    = 500\n",
    "    project_name: str = \"PLC-LD-Detection\"\n",
    "\n",
    "cfg = Config()\n",
    "set_seed(cfg.seed)\n",
    "\n",
    "# Initialize Weights & Biases\n",
    "wandb.init(project=cfg.project_name, config=vars(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402,
     "referenced_widgets": [
      "4424c728032e43968d3915274a49480e",
      "e4985387c5f44e9683c47b08a1de5c2d",
      "1cdbdd39c40a49afa864d29180cdd8cf",
      "b47f22a99068442fba8e0c4ec1044fbf",
      "4995a26bb7c746d282aa2721544637e3",
      "9977b3d8e02e435e84e842cd8a195c61",
      "0f965369993248ac9202b702292aca06",
      "60262507fc5643ef90e927e588a991ff",
      "be227970bcba4faca20d8834ecd3fdce",
      "2975832f3a2043a7ae5328201e198d24",
      "4caf55ab3180437abd9b9f099cfb6195",
      "aeec0ddff6a04281beb312a93b0137f2",
      "ba48c35a82b24a928c904a19271577db",
      "532b3fe55cc94c31a6baacc4c2f0b3d1",
      "3b034951b1c449cb9469e00483be03fa",
      "4962b344f0d74a339b5c59434d4ef0cc",
      "1e60387c03ce44b6b40d940e5c4884f5",
      "8e0d03a571f2421fbd10a342c87ca8d1",
      "6d9be12ea04742249abd8ec014249c09",
      "41f4903b1f24402baa520a835220585b",
      "70a357da60e3412da0e6232c4b992781",
      "4db3f2132ff94395b3254c2184353e2b",
      "3de8a1551bd64858a7574581602b224d",
      "4631c7faab2143f6a3682465162d2b02",
      "233e1474be134128a6c76f42c0018f7f",
      "600e8fcf69e94dc0bd3ec94efccac0db",
      "e129755278ac4dcd9152af6f970a84d1",
      "1b0b5f3e110e465690f9b5e9651a3864",
      "e14ad8c2282d462296a347ac23f8af7b",
      "3db6e62f77fc4287a472c548f5942599",
      "2bb8f84c25b24f14a7b7075ef58c8541",
      "41f3da2260794b62bd2bff0bba587793",
      "ff2a5e26a6cd485781ec76a0ccd031c7",
      "be65d5c9fde946b599a71cc0323784ce",
      "334687e406714632a7a3aef96e70562c",
      "ef955aee621d427b874939ef6cfcdc3a",
      "bedb81c751644b38a87aae39e792c968",
      "4b2649bf3cae4067bffc3799de352b09",
      "a66fd728c90d40a6937fcce7aec39c5d",
      "ddadbb1669f34c72bb2e98862163f239",
      "12b7aeb14261407b88cef37d1c76c1e8",
      "fa0bb81c80994867918f897c5982f688",
      "83d701718cac41aca39c3c8cfebd8c58",
      "4a19552db82141e79fb5fc43a1e2d991",
      "94a6cc4288944eff98ee1e90015b1ae4",
      "a4dd78aac8c243c8b75d9ab1bde725da",
      "76a30b2ea2a04786ab620482e114735e",
      "65eff27f534c45b7a4ca1c5118507d5b",
      "a70ebebcde3d4f40891ec0e7b4eeabdf",
      "94d3b8cfc0fe4e87bc416a2fadd2e7d8",
      "51a5c24ee74e4cc587c93ca68dddd936",
      "4556b172862c408ba730f581a4880c68",
      "76b51411d6d8497caff41763ed0bfd20",
      "4b46a1a3976e4725811980f2ea4b508c",
      "80f099c4c690486383b5373ede603735",
      "7d87a971f0a84673b2301bd5bc7e7f05",
      "8bd33a4c1b4c46c9ab7053b3f05cae12",
      "b538037216be4187b08f727787227eb7",
      "aab95ccca5d1417ebeba1ed9b9494c3b",
      "b1c8c307d32e46459c568f16922bb8ba",
      "8f61d7ba69bb403ebf0cd3979a262791",
      "cf0c00d22641418db0c51a62cadd257f",
      "d6eaf7f984034633a28907c532b35538",
      "cce8015c5b10442f829990505682869e",
      "17459f449eb94967afb3369a87a43167",
      "86a2d3a3dab04214a442aa4555ab1c58",
      "fbc69b422b744ab7828489a33d1a19fe",
      "8e07f0e0fad442559fdc3a86bacd2b22",
      "df47fcc09ef148a7bc0bfb75dc38e13e",
      "62928d4c2c7e4291a0507236de544638",
      "aa8862f032ed49e990f3602323e6d21e",
      "17d6e76db0ce4747af9f44b900c0ad62",
      "7934a6d563994ddface4de914197912c",
      "b37737d511694bcbb1fccf6759647302",
      "0825221848974641adabeba988ce5b7e",
      "83d2d9c23d734507845c17a53532abe7",
      "74cb58cdb0564615bd68a67c96eb5b96",
      "92cfb3ffad4d457999015d13545537a3",
      "cfa4a7b2d5634b7db9886b2ed6ec526a",
      "08eb6c74973b4412ab52aadc3ed19add",
      "0d5a472ebe824000a2c46e91405d6983",
      "60c7f07222184a3b892e883f04b09031",
      "3bf7724e20c349bf893e9b262127796a",
      "83f30e7899f84019bebe646dc7b1431c",
      "cb5fa1823ce54f17adca64031009f34e",
      "18f048e7e096425390f1b1620c2dfc7f",
      "a73ab3d4c4ea4b98965643d00c1c2d96",
      "5bbb2afc04f247d08840a34f7b8ceeb6"
     ]
    },
    "id": "5-ots4VasSuH",
    "outputId": "c7d87706-b88c-4f5d-ef0c-1f331e4a3c8e"
   },
   "outputs": [],
   "source": [
    "# 3. Load and Prepare Data\n",
    "\n",
    "def xml_to_text(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return str(xmltodict.parse(f.read()))\n",
    "\n",
    "texts, labels = [], []\n",
    "for fn in os.listdir(cfg.legit_dir):\n",
    "    if fn.endswith('.xml') and fn.startswith('l'):\n",
    "        legit_path = os.path.join(cfg.legit_dir, fn)\n",
    "        mal_path   = os.path.join(cfg.mal_dir, 'm'+fn[1:])\n",
    "        if os.path.exists(mal_path):\n",
    "            texts.append(xml_to_text(legit_path)); labels.append(0)\n",
    "            texts.append(xml_to_text(mal_path));   labels.append(1)\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts, labels, test_size=cfg.eval_split, random_state=cfg.seed, stratify=labels\n",
    ")\n",
    "\n",
    "dataset = Dataset.from_dict({\n",
    "    'text': train_texts + val_texts,\n",
    "    'label': train_labels + val_labels\n",
    "})\n",
    "\n",
    "# 4. Tokenization\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)\n",
    "\n",
    "def preprocess(examples):\n",
    "    enc = tokenizer(\n",
    "        examples['text'], padding='max_length', truncation=True,\n",
    "        max_length=cfg.max_length\n",
    "    )\n",
    "    enc['labels'] = examples['label']\n",
    "    return enc\n",
    "\n",
    "dataset = dataset.map(preprocess, batched=True)\n",
    "\n",
    "dataset = dataset.train_test_split(test_size=len(val_texts), seed=cfg.seed)\n",
    "train_dataset = dataset['train']\n",
    "eval_dataset  = dataset['test']\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "# 5. Metrics\n",
    "metric_acc = evaluate.load('accuracy')\n",
    "metric_f1  = evaluate.load('f1')\n",
    "def compute_metrics(pred):\n",
    "    logits, labels = pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        **metric_acc.compute(predictions=preds, references=labels),\n",
    "        **metric_f1.compute(predictions=preds, references=labels, average='weighted')\n",
    "    }\n",
    "\n",
    "# 6. TrainingArguments & Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=cfg.output_dir,\n",
    "    num_train_epochs=cfg.epochs,\n",
    "    per_device_train_batch_size=cfg.train_batch_size,\n",
    "    per_device_eval_batch_size=cfg.eval_batch_size,\n",
    "    gradient_accumulation_steps=cfg.accum_steps,\n",
    "    learning_rate=cfg.lr,\n",
    "    weight_decay=cfg.weight_decay,\n",
    "    fp16=cfg.fp16,\n",
    "    logging_steps=cfg.logging_steps,\n",
    "    save_steps=cfg.save_steps,\n",
    "    seed=cfg.seed,\n",
    "    report_to=\"wandb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142,
     "referenced_widgets": [
      "814648cfe61d4749bb1fe7b03b551cca",
      "11715094eecc42ba8cb4de8957d77078",
      "553affc1eb354a9c8bb53d3ea986a75d",
      "52479d45173d40f79edcc42183628244",
      "a6f7d2528ff44b82917901f4a0199268",
      "6a18d6ca4a6e4d9aa24c8cc4d651f3ca",
      "113e27b2508d47e8938d47a3753075f4",
      "bee64d4146c24a5d8b015028b1f9cf89",
      "336084bfe6504ad897c3e27e35990b57",
      "a7e5c4faa1d94b0480c8134d439bca64",
      "183e4ee8fd3b4604839756e2de6d1916"
     ]
    },
    "id": "3uSm8UYLsYU1",
    "outputId": "1d95cb67-544a-473a-c78f-626f9e51bd82"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(cfg.model_name, num_labels=2)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "6reKZr0jt0Tv",
    "outputId": "440e92ed-39d8-4585-f1dd-2044c704f202"
   },
   "outputs": [],
   "source": [
    "# 7. Train & Evaluate\n",
    "trainer.train()\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NU6Who_Xt5wh",
    "outputId": "637846ee-3a0e-4ad5-8963-ed64b63242f7"
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(cfg.output_dir)\n",
    "tokenizer.save_pretrained(cfg.output_dir)\n",
    "print(f\"Model and tokenizer saved to {cfg.output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "_vDtutTovCFD",
    "outputId": "1cfd2288-74f6-42cf-82ca-228f56c7eb6f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "eval_df = pd.DataFrame([eval_results])\n",
    "display(eval_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9DjDf4rhQYdA",
    "outputId": "e0a4a24f-844f-4772-ec58-68a5e1cc2e7a"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Select a random file\n",
    "all_files = [os.path.join(cfg.legit_dir, f) for f in os.listdir(cfg.legit_dir) if f.endswith('.xml') and f.startswith('l')] + \\\n",
    "            [os.path.join(cfg.mal_dir, f) for f in os.listdir(cfg.mal_dir) if f.endswith('.xml') and f.startswith('m')]\n",
    "\n",
    "random_file_path = random.choice(all_files)\n",
    "print(f\"Selected random file: {random_file_path}\")\n",
    "\n",
    "# Determine the true label\n",
    "true_label = 0 if 'legitimate' in random_file_path else 1\n",
    "print(f\"True label: {true_label}\")\n",
    "\n",
    "\n",
    "# Preprocess the file\n",
    "text_to_classify = xml_to_text(random_file_path)\n",
    "processed_input = preprocess({'text': [text_to_classify], 'label': [true_label]})\n",
    "\n",
    "# Convert to PyTorch tensors and move to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_ids = torch.tensor(processed_input['input_ids']).to(device)\n",
    "attention_mask = torch.tensor(processed_input['attention_mask']).to(device)\n",
    "model.to(device) # Ensure model is on the correct device\n",
    "\n",
    "\n",
    "# Make prediction\n",
    "model.eval() # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs.logits\n",
    "    predicted_class = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "\n",
    "# Map predicted class to label name\n",
    "label_map = {0: 'legitimate', 1: 'malicious'}\n",
    "print(f\"Predicted label: {label_map[predicted_class]}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
